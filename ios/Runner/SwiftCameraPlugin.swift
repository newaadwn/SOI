import Flutter
import UIKit
import AVFoundation

// ê°„ë‹¨í•œ ì¹´ë©”ë¼ í”ŒëŸ¬ê·¸ì¸ êµ¬í˜„
public class SwiftCameraPlugin: NSObject, FlutterPlugin, AVCapturePhotoCaptureDelegate {
    var captureSession: AVCaptureSession?
    var photoOutput: AVCapturePhotoOutput?
    var currentDevice: AVCaptureDevice?
    var flashMode: AVCaptureDevice.FlashMode = .off
    var isUsingFrontCamera: Bool = false
    var photoCaptureResult: FlutterResult?
    var currentZoomLevel: Double = 1.0  // í˜„ì¬ ì¤Œ ë ˆë²¨ ì¶”ì 
    
    public static func register(with registrar: FlutterPluginRegistrar) {
        // í”Œë«í¼ ì±„ë„ ë“±ë¡ ë° í•¸ë“¤ëŸ¬ ì„¤ì •
        let channel = FlutterMethodChannel(name: "com.soi.camera", binaryMessenger: registrar.messenger())
        let instance = SwiftCameraPlugin()
        registrar.addMethodCallDelegate(instance, channel: channel)
        
        // ì¹´ë©”ë¼ ì´ˆê¸°í™”
        instance.setupCamera()
        
        // í”Œë«í¼ ë·° ë“±ë¡ - nil ì²´í¬ ì¶”ê°€
        guard let captureSession = instance.captureSession else {
            print("ê²½ê³ : ì¹´ë©”ë¼ ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return
        }
        
        // í”Œë«í¼ ë·° íŒ©í† ë¦¬ ë“±ë¡
        registrar.register(
            CameraPreviewFactory(captureSession: captureSession),
            withId: "com.soi.camera/preview"
        )
    }
    
    // ê¸°ë³¸ ì¹´ë©”ë¼ ì„¤ì •
    func setupCamera() {
        captureSession = AVCaptureSession()
        captureSession?.sessionPreset = .photo
        
        // ê¸°ë³¸ í›„ë©´ ì¹´ë©”ë¼ ì„¤ì •
        if let device = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) {
            currentDevice = device
            beginSession()
        }
    }
    
    // ì¹´ë©”ë¼ ì„¸ì…˜ ì‹œì‘
    func beginSession() {
        guard let session = captureSession, let device = currentDevice else { return }
        
        do {
            // ì¹´ë©”ë¼ ì…ë ¥ ì„¤ì •
            let input = try AVCaptureDeviceInput(device: device)
            if session.canAddInput(input) {
                session.addInput(input)
            }
            
            // ì‚¬ì§„ ì¶œë ¥ ì„¤ì •
            photoOutput = AVCapturePhotoOutput()
            if let photoOutput = photoOutput, session.canAddOutput(photoOutput) {
                // ğŸ¨ ìƒ‰ê³µê°„ ì„¤ì •: sRGB ê°•ì œ (ìƒ‰ìƒ ì¼ê´€ì„± í–¥ìƒ)
                if #available(iOS 11.0, *) {
                    // ê°€ëŠ¥í•œ ìƒ‰ê³µê°„ ì¤‘ sRGB ì„ íƒ
                    if photoOutput.availablePhotoPixelFormatTypes.contains(kCVPixelFormatType_32BGRA) {
                        photoOutput.setPreparedPhotoSettingsArray([
                            AVCapturePhotoSettings(format: [
                                kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
                            ])
                        ], completionHandler: nil)
                        print("ğŸ¨ ì¹´ë©”ë¼ ì¶œë ¥ ìƒ‰ê³µê°„: sRGB (32BGRA) ì„¤ì • ì™„ë£Œ")
                    }
                }
                
                session.addOutput(photoOutput)
                
                // ì‚¬ì§„ ì¶œë ¥ ì—°ê²°ì—ëŠ” ë¯¸ëŸ¬ë§ ì ìš©í•˜ì§€ ì•ŠìŒ (ì›ë³¸ ì´ë¯¸ì§€ ìœ ì§€)
                if let connection = photoOutput.connection(with: .video) {
                    if connection.isVideoMirroringSupported {
                        connection.automaticallyAdjustsVideoMirroring = false
                        connection.isVideoMirrored = false  // ì‚¬ì§„ì€ ë¯¸ëŸ¬ë§ ì—†ì´
                        print("ğŸ”§ ì‚¬ì§„ ì¶œë ¥ ì—°ê²° ë¯¸ëŸ¬ë§ ë¹„í™œì„±í™” (ì›ë³¸ ì´ë¯¸ì§€ ë³´ì¡´)")
                    }
                }
            }
            
            // ì„¸ì…˜ ì‹œì‘
            DispatchQueue.global(qos: .userInitiated).async {
                session.startRunning()
                
                // âœ… ìˆ˜ì •: ì„¸ì…˜ ì•ˆì •í™” í›„ ë¯¸ëŸ¬ë§ ì ìš©
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.3) {
                    self.applyMirroringToAllConnections()
                    print("ğŸ”§ ì¹´ë©”ë¼ ì„¸ì…˜ ì‹œì‘ í›„ ë¯¸ëŸ¬ë§ ì„¤ì • ì™„ë£Œ")
                }
            }
        } catch {
            print("ì¹´ë©”ë¼ ì„¸ì…˜ ì„¤ì • ì˜¤ë¥˜: \(error)")
        }
    }
    
    // í”Œë«í¼ ì±„ë„ ë©”ì„œë“œ ì²˜ë¦¬
    public func handle(_ call: FlutterMethodCall, result: @escaping FlutterResult) {
        switch call.method {
        case "initCamera":
            initCamera(result: result)
        case "takePicture":
            takePicture(result: result)    
        case "switchCamera":
            switchCamera(result: result)
        case "setFlash":
            setFlash(call: call, result: result)
        case "setZoom":
            setZoom(call: call, result: result)
        case "pauseCamera":
            pauseCamera(result: result)
        case "resumeCamera":
            resumeCamera(result: result)
        case "disposeCamera":
            disposeCamera(result: result)
        case "optimizeCamera":
            optimizeCamera(result: result)
        case "getAvailableZoomLevels":
            getAvailableZoomLevels(result: result)
        default:
            result(FlutterMethodNotImplemented)
        }
    }
    
    // ì¹´ë©”ë¼ ì´ˆê¸°í™”
    func initCamera(result: @escaping FlutterResult) {
        if captureSession == nil {
            setupCamera()
        }
        result("Camera initialized")
    }
    
    // ì‚¬ì§„ ì´¬ì˜
    func takePicture(result: @escaping FlutterResult) {
        guard let photoOutput = self.photoOutput else {
            result(FlutterError(code: "NO_PHOTO_OUTPUT", message: "Photo output not available", details: nil))
            return
        }
        
        // ì‚¬ì§„ ì´¬ì˜ ì„¤ì •
        let settings = AVCapturePhotoSettings()
        settings.flashMode = flashMode
        
        // ğŸ¨ ìƒ‰ê³µê°„ì„ sRGBë¡œ ëª…ì‹œì  ì„¤ì • (ìƒ‰ìƒ ì¼ê´€ì„± í–¥ìƒ)
        if #available(iOS 13.0, *) {
            let desiredPriority: AVCapturePhotoOutput.QualityPrioritization = .quality
            let maxSupportedPriority = photoOutput.maxPhotoQualityPrioritization

            if desiredPriority.rawValue <= maxSupportedPriority.rawValue {
                settings.photoQualityPrioritization = desiredPriority
            } else {
                settings.photoQualityPrioritization = maxSupportedPriority
            }
        }
        
        // ìƒ‰ê³µê°„ ì„¤ì •ì€ photoOutputì—ì„œ ì²˜ë¦¬ë¨ (ì•„ë˜ setupPhotoOutput ì°¸ì¡°)
        
        // ì „ë©´ ì¹´ë©”ë¼ì¸ ê²½ìš° íŠ¹ë³„í•œ ì„¤ì • ì¶”ê°€
        if currentDevice?.position == .front {
            print("ğŸ”§ ì „ë©´ ì¹´ë©”ë¼ ì„¤ì • ì ìš©")
            // í•„ìš”ì‹œ ì „ë©´ ì¹´ë©”ë¼ ì „ìš© ì„¤ì • ì¶”ê°€
        }
        
        print("ğŸ“¸ ì‚¬ì§„ ì´¬ì˜ ì‹œì‘ - ì¶œë ¥ ë¯¸ëŸ¬ë§ ë¹„í™œì„±í™” ìƒíƒœ")
        photoCaptureResult = result
        photoOutput.capturePhoto(with: settings, delegate: self)
    }
    
    // ì‚¬ì§„ ì´¬ì˜ ì™„ë£Œ ì²˜ë¦¬
    public func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let error = error {
            photoCaptureResult?(FlutterError(code: "CAPTURE_ERROR", message: error.localizedDescription, details: nil))
            return
        }
        
        // ì´ë¯¸ì§€ ë°ì´í„° ì–»ê¸°
        guard let imageData = photo.fileDataRepresentation() else {
            photoCaptureResult?(FlutterError(code: "NO_IMAGE_DATA", message: "Could not get image data", details: nil))
            return
        }
        
        // í˜„ì¬ ì¹´ë©”ë¼ ìœ„ì¹˜ ì§ì ‘ í™•ì¸
        let isFrontCamera = currentDevice?.position == .front
        print("ğŸ” í˜„ì¬ ì¹´ë©”ë¼ ìœ„ì¹˜: \(isFrontCamera ? "ì „ë©´" : "í›„ë©´")")
        
        // UIImageë¡œ ë³€í™˜
        guard let originalImage = UIImage(data: imageData) else {
            photoCaptureResult?(FlutterError(code: "IMAGE_CONVERSION_ERROR", message: "Could not convert image data to UIImage", details: nil))
            return
        }
        
        print("ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: \(originalImage.size)")
        print("ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€ orientation: \(originalImage.imageOrientation.rawValue)")
        
        // ì´ë¯¸ì§€ ë°©í–¥ ë° ë°˜ì „ ì²˜ë¦¬
        var finalImage: UIImage = originalImage
        
        // ëª¨ë“  ì¹´ë©”ë¼ì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì¢Œìš°ë°˜ì „ í•´ì œ)
        print("ğŸ“¸ \(isFrontCamera ? "ì „ë©´" : "í›„ë©´") ì¹´ë©”ë¼: ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš© (ì¢Œìš°ë°˜ì „ í•´ì œ)")
        
        // ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ JPEG ë°ì´í„°ë¡œ ë³€í™˜
        guard let processedImageData = finalImage.jpegData(compressionQuality: 0.9) else {
            photoCaptureResult?(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Could not convert processed image to JPEG", details: nil))
            return
        }
        
        // ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        let tempDir = NSTemporaryDirectory()
        let filePath = tempDir + "/\(UUID().uuidString).jpg"
        let fileURL = URL(fileURLWithPath: filePath)
        
        do {
            try processedImageData.write(to: fileURL)
            photoCaptureResult?(filePath)
            print("âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: \(filePath)")
        } catch {
            photoCaptureResult?(FlutterError(code: "FILE_SAVE_ERROR", message: error.localizedDescription, details: nil))
        }
    }
    
    // ì´ë¯¸ì§€ ì¢Œìš°ë°˜ì „ ì²˜ë¦¬ - ìµœì¢… ê°œì„  ë²„ì „
    func flipImageHorizontally(_ image: UIImage) -> UIImage {
        // 1. UIImage orientation ë°©ë²• ì‹œë„
        if let cgImage = image.cgImage {
            let flippedImage = UIImage(cgImage: cgImage, scale: image.scale, orientation: .upMirrored)
            print("âœ… ì´ë¯¸ì§€ ì¢Œìš°ë°˜ì „ ì™„ë£Œ (UIImage orientation ë°©ë²•)")
            return flippedImage
        }
        
        // 2. Core Graphics ë°©ë²•ìœ¼ë¡œ í´ë°±
        UIGraphicsBeginImageContextWithOptions(image.size, false, image.scale)
        defer { UIGraphicsEndImageContext() }
        
        guard let context = UIGraphicsGetCurrentContext(),
              let cgImage = image.cgImage else {
            print("âš ï¸ ì¢Œìš°ë°˜ì „ ì‹¤íŒ¨ - ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜")
            return image
        }
        
        // ì¢Œìš°ë°˜ì „ ë³€í™˜ ì ìš©
        context.translateBy(x: image.size.width, y: 0)
        context.scaleBy(x: -1.0, y: 1.0)
        
        // ì´ë¯¸ì§€ ê·¸ë¦¬ê¸°
        context.draw(cgImage, in: CGRect(origin: .zero, size: image.size))
        
        guard let flippedImage = UIGraphicsGetImageFromCurrentImageContext() else {
            print("âš ï¸ Core Graphics ì¢Œìš°ë°˜ì „ ì‹¤íŒ¨ - ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜")
            return image
        }
        
        print("âœ… ì´ë¯¸ì§€ ì¢Œìš°ë°˜ì „ ì™„ë£Œ (Core Graphics ë°©ë²•)")
        return flippedImage
    }
    
    // í›„ë©´ ì¹´ë©”ë¼ ë°©í–¥ ìˆ˜ì • (ìƒí•˜ ë°˜ì „ í•´ê²°)
    func fixBackCameraOrientation(_ image: UIImage) -> UIImage {
        // ì›ë³¸ ì´ë¯¸ì§€ì˜ ë°©í–¥ í™•ì¸
        let originalOrientation = image.imageOrientation
        print("ğŸ“¸ í›„ë©´ ì¹´ë©”ë¼ ì›ë³¸ ë°©í–¥: \(originalOrientation.rawValue)")
        
        guard let cgImage = image.cgImage else {
            print("âš ï¸ í›„ë©´ ì¹´ë©”ë¼ ë°©í–¥ ìˆ˜ì • ì‹¤íŒ¨ - ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜")
            return image
        }
        
        // ì´ë¯¸ ì˜¬ë°”ë¥¸ ë°©í–¥ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if originalOrientation == .up {
            print("âœ… í›„ë©´ ì¹´ë©”ë¼ ì´ë¯¸ ì˜¬ë°”ë¥¸ ë°©í–¥")
            return image
        }
        
        // Core Graphicsë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì˜¬ë°”ë¥¸ ë°©í–¥ìœ¼ë¡œ ê·¸ë¦¬ê¸°
        UIGraphicsBeginImageContextWithOptions(image.size, false, image.scale)
        defer { UIGraphicsEndImageContext() }
        
        image.draw(in: CGRect(origin: .zero, size: image.size))
        
        guard let correctedImage = UIGraphicsGetImageFromCurrentImageContext() else {
            print("âš ï¸ í›„ë©´ ì¹´ë©”ë¼ ë°©í–¥ ìˆ˜ì • ì‹¤íŒ¨ - ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜")
            return image
        }
        
        print("âœ… í›„ë©´ ì¹´ë©”ë¼ ë°©í–¥ ìˆ˜ì • ì™„ë£Œ")
        return correctedImage
    }
    
    // í”„ë¦¬ë·° ì—°ê²°ì—ë§Œ ë¯¸ëŸ¬ë§ ì ìš© (ì‚¬ì§„ ì¶œë ¥ ì œì™¸)
    func applyMirroringToAllConnections() {
        guard let captureSession = captureSession else { return }
        
        // í˜„ì¬ ì¹´ë©”ë¼ íƒ€ì… í™•ì¸
        let isFrontCamera = currentDevice?.position == .front
        
        // ëª¨ë“  ì¶œë ¥ì˜ ì—°ê²°ì„ í™•ì¸í•˜ê³  ì ì ˆíˆ ë¯¸ëŸ¬ë§ ì ìš©
        for output in captureSession.outputs {
            // ì‚¬ì§„ ì¶œë ¥ì€ í•­ìƒ ë¯¸ëŸ¬ë§ ë¹„í™œì„±í™” (ì›ë³¸ ì´ë¯¸ì§€ ìœ ì§€)
            if output is AVCapturePhotoOutput {
                for connection in output.connections {
                    if connection.isVideoMirroringSupported {
                        connection.automaticallyAdjustsVideoMirroring = false
                        connection.isVideoMirrored = false
                        print("ğŸ”§ ì‚¬ì§„ ì¶œë ¥ ì—°ê²° ë¯¸ëŸ¬ë§ ë¹„í™œì„±í™”")
                    }
                }
            } else {
                // í”„ë¦¬ë·° ì¶œë ¥ì€ ì „ë©´ ì¹´ë©”ë¼ì—ì„œë§Œ ë¯¸ëŸ¬ë§ í™œì„±í™”
                for connection in output.connections {
                    if connection.isVideoMirroringSupported {
                        connection.automaticallyAdjustsVideoMirroring = false
                        connection.isVideoMirrored = isFrontCamera
                        print("ğŸ”§ í”„ë¦¬ë·° ì¶œë ¥ ì—°ê²° ë¯¸ëŸ¬ë§: \(isFrontCamera ? "ì „ë©´ ì¹´ë©”ë¼ - í™œì„±í™”" : "í›„ë©´ ì¹´ë©”ë¼ - ë¹„í™œì„±í™”")")
                    }
                }
            }
        }
    }
    
    // ì¹´ë©”ë¼ ì „í™˜
    func switchCamera(result: @escaping FlutterResult) {
        guard let captureSession = captureSession,
              let currentInput = captureSession.inputs.first as? AVCaptureDeviceInput else {
            result(FlutterError(code: "NO_CAMERA", message: "No current camera", details: nil))
            return
        }
        
        captureSession.beginConfiguration()
        captureSession.removeInput(currentInput)
        
        // ì „/í›„ë©´ ì¹´ë©”ë¼ ì „í™˜
        isUsingFrontCamera.toggle()
        let newPosition: AVCaptureDevice.Position = isUsingFrontCamera ? .front : .back
        
        if let newDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: newPosition) {
            currentDevice = newDevice
            do {
                let newInput = try AVCaptureDeviceInput(device: newDevice)
                if captureSession.canAddInput(newInput) {
                    captureSession.addInput(newInput)
                }
            } catch {
                result(FlutterError(code: "SWITCH_ERROR", message: error.localizedDescription, details: nil))
                captureSession.commitConfiguration()
                return
            }
        }
        
        captureSession.commitConfiguration()
        
        // âœ… ìˆ˜ì •: ì¹´ë©”ë¼ ì „í™˜ í›„ ì•ˆì •í™” ì‹œê°„ì„ ë‘ê³  ë¯¸ëŸ¬ë§ ì„¤ì • ì ìš©
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.2) {
            self.applyMirroringToAllConnections()
            print("ğŸ”§ ì¹´ë©”ë¼ ì „í™˜ ì™„ë£Œ - \(self.isUsingFrontCamera ? "ì „ë©´" : "í›„ë©´") ì¹´ë©”ë¼, ë¯¸ëŸ¬ë§ ì¬ì„¤ì •")
        }
        
        result("Camera switched")
    }
    
    // í”Œë˜ì‹œ ì„¤ì •
    func setFlash(call: FlutterMethodCall, result: @escaping FlutterResult) {
        guard let args = call.arguments as? [String: Any],
              let isOn = args["isOn"] as? Bool else {
            result(FlutterError(code: "INVALID_ARGS", message: "Missing or invalid isOn parameter", details: nil))
            return
        }
        
        flashMode = isOn ? .on : .off
        result("Flash set to \(isOn ? "on" : "off")")
    }
    
    // ì¤Œ ì„¤ì • - ë¬¼ë¦¬ì  ë Œì¦ˆ ì „í™˜ ì§€ì›
    func setZoom(call: FlutterMethodCall, result: @escaping FlutterResult) {
        guard let args = call.arguments as? [String: Any],
              let zoomValue = args["zoomValue"] as? Double else {
            result(FlutterError(code: "INVALID_ARGS", message: "Missing or invalid zoomValue parameter", details: nil))
            return
        }
        
        guard let captureSession = captureSession else {
            result(FlutterError(code: "NO_SESSION", message: "No capture session available", details: nil))
            return
        }
        
        // ì „ë©´ ì¹´ë©”ë¼ëŠ” ì¤Œ ë³€ê²½ ë¶ˆê°€
        if isUsingFrontCamera {
            result("Front camera does not support zoom")
            return
        }
        
        currentZoomLevel = zoomValue
        
        // ë¬¼ë¦¬ì  ë§ì› ì¹´ë©”ë¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        let hasTelephoto = AVCaptureDevice.default(.builtInTelephotoCamera, for: .video, position: .back) != nil
        
        // ì¤Œ ë ˆë²¨ì— ë”°ë¥¸ ì¹´ë©”ë¼ ì„ íƒ
        let targetCameraType: AVCaptureDevice.DeviceType
        let digitalZoomFactor: CGFloat
        
        if zoomValue < 0.75 {
            // 0.5x - ì´ˆê´‘ê° ì¹´ë©”ë¼
            targetCameraType = .builtInUltraWideCamera
            digitalZoomFactor = CGFloat(zoomValue * 2.0)  // 0.5x = 1.0 factor on ultra wide
            print("ğŸ“± ì¤Œ ì„¤ì •: 0.5x ì´ˆê´‘ê° ì¹´ë©”ë¼ ì‚¬ìš©")
        } else if zoomValue < 1.5 {
            // 1.0x - ì¼ë°˜ ê´‘ê° ì¹´ë©”ë¼
            targetCameraType = .builtInWideAngleCamera
            digitalZoomFactor = CGFloat(zoomValue)
            print("ğŸ“± ì¤Œ ì„¤ì •: 1.0x ê´‘ê° ì¹´ë©”ë¼ ì‚¬ìš©")
        } else if zoomValue < 2.5 && hasTelephoto {
            // 2.0x - ë¬¼ë¦¬ì  ë§ì› ì¹´ë©”ë¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            targetCameraType = .builtInTelephotoCamera
            digitalZoomFactor = 1.0  // ë§ì› ì¹´ë©”ë¼ì˜ ê¸°ë³¸ ë°°ìœ¨
            print("ğŸ“± ì¤Œ ì„¤ì •: 2.0x ë¬¼ë¦¬ì  ë§ì› ì¹´ë©”ë¼ ì‚¬ìš©")
        } else if zoomValue >= 3.0 && hasTelephoto {
            // 3.0x - ë¬¼ë¦¬ì  ë§ì› ì¹´ë©”ë¼ê°€ ìˆìœ¼ë©´ ë§ì› ì¹´ë©”ë¼ì—ì„œ ë””ì§€í„¸ ì¤Œ
            targetCameraType = .builtInTelephotoCamera
            digitalZoomFactor = CGFloat(zoomValue / 2.0)  // ë§ì› ì¹´ë©”ë¼ ê¸°ì¤€ìœ¼ë¡œ ë””ì§€í„¸ ì¤Œ
            print("ğŸ“± ì¤Œ ì„¤ì •: 3.0x ë¬¼ë¦¬ì  ë§ì› ì¹´ë©”ë¼ + ë””ì§€í„¸ ì¤Œ ì‚¬ìš©")
        } else {
            // ë§ì› ì¹´ë©”ë¼ê°€ ì—†ê±°ë‚˜ ë‹¤ë¥¸ ê²½ìš° - ê´‘ê°ì—ì„œ ë””ì§€í„¸ ì¤Œ
            targetCameraType = .builtInWideAngleCamera
            digitalZoomFactor = CGFloat(zoomValue)
            print("ğŸ“± ì¤Œ ì„¤ì •: \(zoomValue)x ê´‘ê° ì¹´ë©”ë¼ ë””ì§€í„¸ ì¤Œ ì‚¬ìš© (ë§ì› ì¹´ë©”ë¼ ì—†ìŒ)")
        }
        
        // ëª©í‘œ ì¹´ë©”ë¼ ê°€ì ¸ì˜¤ê¸°
        guard let newDevice = AVCaptureDevice.default(targetCameraType, for: .video, position: .back) else {
            // ëª©í‘œ ì¹´ë©”ë¼ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ì¹´ë©”ë¼ì—ì„œ ë””ì§€í„¸ ì¤Œë§Œ ì ìš©
            if let currentDevice = currentDevice {
                do {
                    try currentDevice.lockForConfiguration()
                    let maxZoom = currentDevice.activeFormat.videoMaxZoomFactor
                    let finalZoom = min(CGFloat(zoomValue), maxZoom)
                    currentDevice.ramp(toVideoZoomFactor: finalZoom, withRate: 2.0)
                    currentDevice.unlockForConfiguration()
                    result("Digital zoom set to \(zoomValue)x")
                } catch {
                    result(FlutterError(code: "ZOOM_ERROR", message: error.localizedDescription, details: nil))
                }
            }
            return
        }
        
        // ì¹´ë©”ë¼ê°€ ë³€ê²½ë˜ì–´ì•¼ í•˜ëŠ” ê²½ìš°
        if newDevice != currentDevice {
            captureSession.beginConfiguration()
            
            // ê¸°ì¡´ ì…ë ¥ ì œê±°
            if let currentInput = captureSession.inputs.first as? AVCaptureDeviceInput {
                captureSession.removeInput(currentInput)
            }
            
            // ìƒˆ ì…ë ¥ ì¶”ê°€
            do {
                let newInput = try AVCaptureDeviceInput(device: newDevice)
                if captureSession.canAddInput(newInput) {
                    captureSession.addInput(newInput)
                    currentDevice = newDevice
                }
                
                // ë””ì§€í„¸ ì¤Œ ì ìš©
                try newDevice.lockForConfiguration()
                let maxZoom = newDevice.activeFormat.videoMaxZoomFactor
                let finalZoom = min(digitalZoomFactor, maxZoom)
                newDevice.videoZoomFactor = finalZoom
                newDevice.unlockForConfiguration()
                
            } catch {
                result(FlutterError(code: "CAMERA_SWITCH_ERROR", message: error.localizedDescription, details: nil))
                captureSession.commitConfiguration()
                return
            }
            
            captureSession.commitConfiguration()
            
            // ë¯¸ëŸ¬ë§ ì¬ì„¤ì •
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.2) {
                self.applyMirroringToAllConnections()
            }
            
            result("Zoom set to \(zoomValue)x with camera switch")
        } else {
            // ê°™ì€ ì¹´ë©”ë¼ì—ì„œ ë””ì§€í„¸ ì¤Œë§Œ ì¡°ì •
            do {
                try currentDevice?.lockForConfiguration()
                let maxZoom = currentDevice?.activeFormat.videoMaxZoomFactor ?? 1.0
                let finalZoom = min(digitalZoomFactor, maxZoom)
                currentDevice?.videoZoomFactor = finalZoom
                currentDevice?.unlockForConfiguration()
                result("Zoom adjusted to \(zoomValue)x")
            } catch {
                result(FlutterError(code: "ZOOM_ERROR", message: error.localizedDescription, details: nil))
            }
        }
    }
    
    // ì¹´ë©”ë¼ ì„¸ì…˜ ì¼ì‹œ ì¤‘ì§€
    func pauseCamera(result: @escaping FlutterResult) {
        guard let captureSession = captureSession else {
            result(FlutterError(code: "SESSION_ERROR", message: "Camera session is not initialized", details: nil))
            return
        }
        
        if captureSession.isRunning {
            captureSession.stopRunning()
        }
        
        result("Camera paused")
    }
    
    // ì¹´ë©”ë¼ ì„¸ì…˜ ì¬ê°œ
    func resumeCamera(result: @escaping FlutterResult) {
        guard let captureSession = captureSession else {
            result(FlutterError(code: "SESSION_ERROR", message: "Camera session is not initialized", details: nil))
            return
        }
        
        if !captureSession.isRunning {
            DispatchQueue.global(qos: .userInitiated).async {
                captureSession.startRunning()
                
                // âœ… ìˆ˜ì •: ì„¸ì…˜ ì¬ê°œ í›„ ì•ˆì •í™” ì‹œê°„ì„ ë‘ê³  ë¯¸ëŸ¬ë§ ì¬ì„¤ì •
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.3) {
                    self.applyMirroringToAllConnections()
                    print("ğŸ”§ ì¹´ë©”ë¼ ì„¸ì…˜ ì¬ê°œ í›„ ë¯¸ëŸ¬ë§ ì„¤ì • ì™„ë£Œ")
                }
            }
        }
        
        result("Camera resumed")
    }
    
    // ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ í•´ì œ
    func disposeCamera(result: @escaping FlutterResult) {
        guard let captureSession = captureSession else {
            result(FlutterError(code: "SESSION_ERROR", message: "Camera session is not initialized", details: nil))
            return
        }
        
        captureSession.stopRunning()
        result("Camera disposed")
    }
    
    // ì¹´ë©”ë¼ ìµœì í™” - ê°„ë‹¨í•œ êµ¬í˜„
    func optimizeCamera(result: @escaping FlutterResult) {
        guard let currentDevice = currentDevice else {
            result(FlutterError(code: "NO_CAMERA", message: "No camera available", details: nil))
            return
        }
        
        do {
            try currentDevice.lockForConfiguration()
            
            // ìë™ ì´ˆì  ì„¤ì •
            if currentDevice.isFocusModeSupported(.continuousAutoFocus) {
                currentDevice.focusMode = .continuousAutoFocus
            }
            
            // ìë™ ë…¸ì¶œ ì„¤ì •
            if currentDevice.isExposureModeSupported(.continuousAutoExposure) {
                currentDevice.exposureMode = .continuousAutoExposure
            }
            
            currentDevice.unlockForConfiguration()
            result("Camera optimized")
        } catch {
            result(FlutterError(code: "OPTIMIZATION_ERROR", message: error.localizedDescription, details: nil))
        }
    }
    
    // MARK: - ì´ë¯¸ì§€ ì²˜ë¦¬ í—¬í¼ ë©”ì„œë“œ
    
    // ì‚¬ìš© ê°€ëŠ¥í•œ ì¤Œ ë ˆë²¨ í™•ì¸ - ë¬¼ë¦¬ì  ì¹´ë©”ë¼ êµ¬ì„±ì— ë”°ë¥¸ ì •í™•í•œ ë ˆë²¨ ë°˜í™˜
    func getAvailableZoomLevels(result: @escaping FlutterResult) {
        var levels: [Double] = []
        var hasUltraWide = false
        var hasTelephoto = false
        
        // í›„ë©´ ì¹´ë©”ë¼ë§Œ ì¤Œ ì§€ì›
        if !isUsingFrontCamera {
            // ì´ˆê´‘ê° ì¹´ë©”ë¼ ì²´í¬ (0.5x)
            if AVCaptureDevice.default(.builtInUltraWideCamera, for: .video, position: .back) != nil {
                hasUltraWide = true
                levels.append(0.5)
            }
            
            // ê´‘ê° ì¹´ë©”ë¼ëŠ” í•­ìƒ ìˆìŒ (1.0x)
            levels.append(1.0)
            
            // ë§ì› ì¹´ë©”ë¼ ì²´í¬
            let telephotoDevice = AVCaptureDevice.default(.builtInTelephotoCamera, for: .video, position: .back)
            if let telephoto = telephotoDevice {
                hasTelephoto = true
                
                // ë§ì› ì¹´ë©”ë¼ì˜ ì‹¤ì œ ì¤Œ ë²”ìœ„ í™•ì¸
                let minZoom = Double(telephoto.minAvailableVideoZoomFactor)
                let maxZoom = Double(telephoto.maxAvailableVideoZoomFactor)
                
                print("ğŸ“± ë§ì› ì¹´ë©”ë¼ ì¤Œ ë²”ìœ„: \(minZoom)x - \(maxZoom)x")
                
                // ë§ì› ì¹´ë©”ë¼ê°€ 2xë¥¼ ì§€ì›í•˜ë©´ ì¶”ê°€
                if minZoom <= 2.0 && maxZoom >= 2.0 {
                    levels.append(2.0)
                }
                
                // ë§ì› ì¹´ë©”ë¼ê°€ 3xë¥¼ ì§€ì›í•˜ë©´ ì¶”ê°€ (ë¬¼ë¦¬ì  ë§ì›ìœ¼ë¡œ)
                if minZoom <= 3.0 && maxZoom >= 3.0 {
                    levels.append(3.0)
                }
            } else {
                // ë§ì› ì¹´ë©”ë¼ê°€ ì—†ëŠ” ê²½ìš°
                print("ğŸ“± ë¬¼ë¦¬ì  ë§ì› ì¹´ë©”ë¼ ì—†ìŒ")
                
                // í˜„ì¬ ê´‘ê° ì¹´ë©”ë¼ì˜ ë””ì§€í„¸ ì¤Œ ë²”ìœ„ í™•ì¸
                if let wideDevice = currentDevice {
                    let maxDigitalZoom = Double(wideDevice.maxAvailableVideoZoomFactor)
                    print("ğŸ“± ê´‘ê° ì¹´ë©”ë¼ ìµœëŒ€ ë””ì§€í„¸ ì¤Œ: \(maxDigitalZoom)x")
                    
                    // ë””ì§€í„¸ ì¤Œìœ¼ë¡œ 2x ì œê³µ
                    if maxDigitalZoom >= 2.0 {
                        levels.append(2.0)
                    }
                    
                    // ë””ì§€í„¸ ì¤Œìœ¼ë¡œ 3x ì œê³µ (ë§ì› ì¹´ë©”ë¼ê°€ ì—†ì„ ë•Œë§Œ)
                    if maxDigitalZoom >= 3.0 {
                        levels.append(3.0)
                    }
                }
            }
        } else {
            // ì „ë©´ ì¹´ë©”ë¼ëŠ” ì¤Œ ë¯¸ì§€ì›
            levels.append(1.0)
        }
        
        // ì •ë ¬
        levels.sort()
        
        print("ğŸ“± ë””ë°”ì´ìŠ¤ ì¹´ë©”ë¼ êµ¬ì„±:")
        print("   - ì´ˆê´‘ê°: \(hasUltraWide ? "ìˆìŒ" : "ì—†ìŒ")")
        print("   - ë§ì›: \(hasTelephoto ? "ìˆìŒ" : "ì—†ìŒ")")
        print("ğŸ“± ìµœì¢… ì‚¬ìš© ê°€ëŠ¥í•œ ì¤Œ ë ˆë²¨: \(levels)")
        
        result(levels)
    }
}

// ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìœ„í•œ í”Œë«í¼ ë·° íŒ©í† ë¦¬
class CameraPreviewFactory: NSObject, FlutterPlatformViewFactory {
    private let captureSession: AVCaptureSession
    
    init(captureSession: AVCaptureSession) {
        self.captureSession = captureSession
        super.init()
    }
    
    func create(withFrame frame: CGRect, viewIdentifier viewId: Int64, arguments args: Any?) -> FlutterPlatformView {
        return CameraPreviewView(
            frame: frame,
            viewIdentifier: viewId,
            arguments: args,
            captureSession: captureSession
        )
    }
    
    func createArgsCodec() -> FlutterMessageCodec & NSObjectProtocol {
        return FlutterStandardMessageCodec.sharedInstance()
    }
}

// ë¯¸ë¦¬ë³´ê¸° ë·° ë ˆì´ì–´ í´ë˜ìŠ¤
class PreviewView: UIView {
    override func layoutSubviews() {
        super.layoutSubviews()
        if let layer = layer as? AVCaptureVideoPreviewLayer {
            layer.videoGravity = .resizeAspectFill
            layer.connection?.videoOrientation = .portrait
            
            // âœ… ìˆ˜ì •: ë¯¸ëŸ¬ë§ ì„¤ì •ì„ SwiftCameraPlugin.applyMirroringToAllConnections()ì—ì„œë§Œ ì²˜ë¦¬
            // ì¤‘ë³µ ë¯¸ëŸ¬ë§ ì„¤ì • ì œê±°ë¡œ ê²½ìŸ ìƒíƒœ ë°©ì§€
            print("ğŸ”§ PreviewView layoutSubviews - ë¯¸ëŸ¬ë§ì€ í”ŒëŸ¬ê·¸ì¸ì—ì„œ í†µí•© ê´€ë¦¬")
        }
    }
    
    override class var layerClass: AnyClass {
        return AVCaptureVideoPreviewLayer.self
    }
}

// ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸° í”Œë«í¼ ë·°
class CameraPreviewView: NSObject, FlutterPlatformView {
    private var _view: PreviewView
    
    init(frame: CGRect, viewIdentifier: Int64, arguments args: Any?, captureSession: AVCaptureSession) {
        _view = PreviewView(frame: frame)
        super.init()
        
        // ë·° ë ˆì´ì–´ ì„¤ì •
        if let previewLayer = _view.layer as? AVCaptureVideoPreviewLayer {
            previewLayer.session = captureSession
            previewLayer.videoGravity = .resizeAspectFill
            previewLayer.connection?.videoOrientation = .portrait
            
            // âœ… ìˆ˜ì •: ë¯¸ëŸ¬ë§ ì„¤ì •ì„ SwiftCameraPlugin.applyMirroringToAllConnections()ì—ì„œë§Œ ì²˜ë¦¬
            // ì¤‘ë³µ ë¯¸ëŸ¬ë§ ì„¤ì • ì œê±°ë¡œ ê²½ìŸ ìƒíƒœ ë°©ì§€
            print("ğŸ”§ CameraPreviewView ì´ˆê¸°í™” - ë¯¸ëŸ¬ë§ì€ í”ŒëŸ¬ê·¸ì¸ì—ì„œ í†µí•© ê´€ë¦¬")
        }
        
        _view.frame = frame
        _view.autoresizingMask = [.flexibleWidth, .flexibleHeight]
        
        // ì„¸ì…˜ì´ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë©´ ì‹œì‘
        if !captureSession.isRunning {
            DispatchQueue.global(qos: .userInitiated).async {
                captureSession.startRunning()
            }
        }
    }
    
    func view() -> UIView {
        return _view
    }
}
