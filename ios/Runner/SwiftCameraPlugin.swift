import Flutter
import UIKit
import AVFoundation

// ê°„ë‹¨í•œ ì¹´ë©”ë¼ í”ŒëŸ¬ê·¸ì¸ êµ¬í˜„
public class SwiftCameraPlugin: NSObject, FlutterPlugin, AVCapturePhotoCaptureDelegate {
    var captureSession: AVCaptureSession?
    var photoOutput: AVCapturePhotoOutput?
    var currentDevice: AVCaptureDevice?
    var flashMode: AVCaptureDevice.FlashMode = .off
    var isUsingFrontCamera: Bool = false
    var photoCaptureResult: FlutterResult?
    
    public static func register(with registrar: FlutterPluginRegistrar) {
        // í”Œëž«í¼ ì±„ë„ ë“±ë¡ ë° í•¸ë“¤ëŸ¬ ì„¤ì •
        let channel = FlutterMethodChannel(name: "com.soi.camera", binaryMessenger: registrar.messenger())
        let instance = SwiftCameraPlugin()
        registrar.addMethodCallDelegate(instance, channel: channel)
        
        // ì¹´ë©”ë¼ ì´ˆê¸°í™”
        instance.setupCamera()
        
        // í”Œëž«í¼ ë·° ë“±ë¡ - nil ì²´í¬ ì¶”ê°€
        guard let captureSession = instance.captureSession else {
            print("ê²½ê³ : ì¹´ë©”ë¼ ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return
        }
        
        // í”Œëž«í¼ ë·° íŒ©í† ë¦¬ ë“±ë¡
        registrar.register(
            CameraPreviewFactory(captureSession: captureSession),
            withId: "com.soi.camera/preview"
        )
    }
    
    // ê¸°ë³¸ ì¹´ë©”ë¼ ì„¤ì •
    func setupCamera() {
        captureSession = AVCaptureSession()
        captureSession?.sessionPreset = .photo
        
        // ê¸°ë³¸ í›„ë©´ ì¹´ë©”ë¼ ì„¤ì •
        if let device = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) {
            currentDevice = device
            beginSession()
        }
    }
    
    // ì¹´ë©”ë¼ ì„¸ì…˜ ì‹œìž‘
    func beginSession() {
        guard let session = captureSession, let device = currentDevice else { return }
        
        do {
            // ì¹´ë©”ë¼ ìž…ë ¥ ì„¤ì •
            let input = try AVCaptureDeviceInput(device: device)
            if session.canAddInput(input) {
                session.addInput(input)
            }
            
            // ì‚¬ì§„ ì¶œë ¥ ì„¤ì •
            photoOutput = AVCapturePhotoOutput()
            if let photoOutput = photoOutput, session.canAddOutput(photoOutput) {
                session.addOutput(photoOutput)
            }
            
            // ì„¸ì…˜ ì‹œìž‘
            DispatchQueue.global(qos: .userInitiated).async {
                session.startRunning()
            }
        } catch {
            print("ì¹´ë©”ë¼ ì„¸ì…˜ ì„¤ì • ì˜¤ë¥˜: \(error)")
        }
    }
    
    // í”Œëž«í¼ ì±„ë„ ë©”ì„œë“œ ì²˜ë¦¬
    public func handle(_ call: FlutterMethodCall, result: @escaping FlutterResult) {
        switch call.method {
        case "initCamera":
            initCamera(result: result)
        case "takePicture":
            takePicture(result: result)    
        case "switchCamera":
            switchCamera(result: result)
        case "setFlash":
            setFlash(call: call, result: result)
        case "pauseCamera":
            pauseCamera(result: result)
        case "resumeCamera":
            resumeCamera(result: result)
        case "disposeCamera":
            disposeCamera(result: result)
        case "optimizeCamera":
            optimizeCamera(result: result)
        default:
            result(FlutterMethodNotImplemented)
        }
    }
    
    // ì¹´ë©”ë¼ ì´ˆê¸°í™”
    func initCamera(result: @escaping FlutterResult) {
        if captureSession == nil {
            setupCamera()
        }
        result("Camera initialized")
    }
    
    // ì‚¬ì§„ ì´¬ì˜
    func takePicture(result: @escaping FlutterResult) {
        guard let photoOutput = self.photoOutput else {
            result(FlutterError(code: "NO_PHOTO_OUTPUT", message: "Photo output not available", details: nil))
            return
        }
        
        // ì‚¬ì§„ ì´¬ì˜ ì„¤ì •
        let settings = AVCapturePhotoSettings()
        settings.flashMode = flashMode
        
        // ì „ë©´ ì¹´ë©”ë¼ì¸ ê²½ìš° íŠ¹ë³„í•œ ì„¤ì • ì¶”ê°€
        if currentDevice?.position == .front {
            print("ðŸ”§ ì „ë©´ ì¹´ë©”ë¼ ì„¤ì • ì ìš©")
            // í•„ìš”ì‹œ ì „ë©´ ì¹´ë©”ë¼ ì „ìš© ì„¤ì • ì¶”ê°€
        }
        
        photoCaptureResult = result
        photoOutput.capturePhoto(with: settings, delegate: self)
    }
    
    // ì‚¬ì§„ ì´¬ì˜ ì™„ë£Œ ì²˜ë¦¬
    public func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let error = error {
            photoCaptureResult?(FlutterError(code: "CAPTURE_ERROR", message: error.localizedDescription, details: nil))
            return
        }
        
        // ì´ë¯¸ì§€ ë°ì´í„° ì–»ê¸°
        guard let imageData = photo.fileDataRepresentation() else {
            photoCaptureResult?(FlutterError(code: "NO_IMAGE_DATA", message: "Could not get image data", details: nil))
            return
        }
        
        // í˜„ìž¬ ì¹´ë©”ë¼ ìœ„ì¹˜ ì§ì ‘ í™•ì¸ (ìƒíƒœ ë³€ìˆ˜ ëŒ€ì‹ )
        let isFrontCamera = currentDevice?.position == .front
        print("ðŸ” í˜„ìž¬ ì¹´ë©”ë¼ ìœ„ì¹˜: \(currentDevice?.position == .front ? "ì „ë©´" : "í›„ë©´")")
        print("ðŸ” isUsingFrontCamera ë³€ìˆ˜: \(isUsingFrontCamera)")
        print("ðŸ” ì‹¤ì œ ë””ë°”ì´ìŠ¤ position: \(currentDevice?.position.rawValue ?? -1)")
        
        // UIImageë¡œ ë³€í™˜
        guard let originalImage = UIImage(data: imageData) else {
            photoCaptureResult?(FlutterError(code: "IMAGE_CONVERSION_ERROR", message: "Could not convert image data to UIImage", details: nil))
            return
        }
        
        // ëª¨ë“  ì¹´ë©”ë¼ì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì¢Œìš°ë°˜ì „ ì²˜ë¦¬ ì•ˆí•¨)
        let finalImage: UIImage = originalImage
        
        if isFrontCamera {
            print("ðŸ“¸ ì „ë©´ ì¹´ë©”ë¼ ì´¬ì˜ - ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš© (ì¢Œìš°ë°˜ì „ ì—†ìŒ)")
        } else {
            print("ðŸ“¸ í›„ë©´ ì¹´ë©”ë¼ ì´¬ì˜ - ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©")
        }
        
        // ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ JPEG ë°ì´í„°ë¡œ ë³€í™˜
        guard let processedImageData = finalImage.jpegData(compressionQuality: 0.9) else {
            photoCaptureResult?(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Could not convert processed image to JPEG", details: nil))
            return
        }
        
        // ìž„ì‹œ íŒŒì¼ë¡œ ì €ìž¥
        let tempDir = NSTemporaryDirectory()
        let filePath = tempDir + "/\(UUID().uuidString).jpg"
        let fileURL = URL(fileURLWithPath: filePath)
        
        do {
            try processedImageData.write(to: fileURL)
            photoCaptureResult?(filePath)
            print("âœ… ì´ë¯¸ì§€ ì €ìž¥ ì™„ë£Œ: \(filePath)")
        } catch {
            photoCaptureResult?(FlutterError(code: "FILE_SAVE_ERROR", message: error.localizedDescription, details: nil))
        }
    }
    
    // ì¹´ë©”ë¼ ì „í™˜
    func switchCamera(result: @escaping FlutterResult) {
        guard let captureSession = captureSession,
              let currentInput = captureSession.inputs.first as? AVCaptureDeviceInput else {
            result(FlutterError(code: "NO_CAMERA", message: "No current camera", details: nil))
            return
        }
        
        captureSession.beginConfiguration()
        captureSession.removeInput(currentInput)
        
        // ì „/í›„ë©´ ì¹´ë©”ë¼ ì „í™˜
        isUsingFrontCamera.toggle()
        let newPosition: AVCaptureDevice.Position = isUsingFrontCamera ? .front : .back
        
        if let newDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: newPosition) {
            currentDevice = newDevice
            do {
                let newInput = try AVCaptureDeviceInput(device: newDevice)
                if captureSession.canAddInput(newInput) {
                    captureSession.addInput(newInput)
                }
            } catch {
                result(FlutterError(code: "SWITCH_ERROR", message: error.localizedDescription, details: nil))
                captureSession.commitConfiguration()
                return
            }
        }
        
        captureSession.commitConfiguration()
        result("Camera switched")
    }
    
    // í”Œëž˜ì‹œ ì„¤ì •
    func setFlash(call: FlutterMethodCall, result: @escaping FlutterResult) {
        guard let args = call.arguments as? [String: Any],
              let isOn = args["isOn"] as? Bool else {
            result(FlutterError(code: "INVALID_ARGS", message: "Missing or invalid isOn parameter", details: nil))
            return
        }
        
        flashMode = isOn ? .on : .off
        result("Flash set to \(isOn ? "on" : "off")")
    }
    
    // ì¹´ë©”ë¼ ì„¸ì…˜ ì¼ì‹œ ì¤‘ì§€
    func pauseCamera(result: @escaping FlutterResult) {
        guard let captureSession = captureSession else {
            result(FlutterError(code: "SESSION_ERROR", message: "Camera session is not initialized", details: nil))
            return
        }
        
        if captureSession.isRunning {
            captureSession.stopRunning()
        }
        
        result("Camera paused")
    }
    
    // ì¹´ë©”ë¼ ì„¸ì…˜ ìž¬ê°œ
    func resumeCamera(result: @escaping FlutterResult) {
        guard let captureSession = captureSession else {
            result(FlutterError(code: "SESSION_ERROR", message: "Camera session is not initialized", details: nil))
            return
        }
        
        if !captureSession.isRunning {
            DispatchQueue.global(qos: .userInitiated).async {
                captureSession.startRunning()
            }
        }
        
        result("Camera resumed")
    }
    
    // ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ í•´ì œ
    func disposeCamera(result: @escaping FlutterResult) {
        guard let captureSession = captureSession else {
            result(FlutterError(code: "SESSION_ERROR", message: "Camera session is not initialized", details: nil))
            return
        }
        
        captureSession.stopRunning()
        result("Camera disposed")
    }
    
    // ì¹´ë©”ë¼ ìµœì í™” - ê°„ë‹¨í•œ êµ¬í˜„
    func optimizeCamera(result: @escaping FlutterResult) {
        guard let currentDevice = currentDevice else {
            result(FlutterError(code: "NO_CAMERA", message: "No camera available", details: nil))
            return
        }
        
        do {
            try currentDevice.lockForConfiguration()
            
            // ìžë™ ì´ˆì  ì„¤ì •
            if currentDevice.isFocusModeSupported(.continuousAutoFocus) {
                currentDevice.focusMode = .continuousAutoFocus
            }
            
            // ìžë™ ë…¸ì¶œ ì„¤ì •
            if currentDevice.isExposureModeSupported(.continuousAutoExposure) {
                currentDevice.exposureMode = .continuousAutoExposure
            }
            
            currentDevice.unlockForConfiguration()
            result("Camera optimized")
        } catch {
            result(FlutterError(code: "OPTIMIZATION_ERROR", message: error.localizedDescription, details: nil))
        }
    }
    
    // MARK: - ì´ë¯¸ì§€ ì²˜ë¦¬ í—¬í¼ ë©”ì„œë“œ
    
    /// ì´ë¯¸ì§€ë¥¼ ì¢Œìš°ë°˜ì „ì‹œí‚¤ëŠ” ë©”ì„œë“œ (ì „ë©´ ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸°ì™€ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•¨)
    private func flipImageHorizontally(_ image: UIImage) -> UIImage {
        // Core Graphicsë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì¢Œìš°ë°˜ì „
        guard let cgImage = image.cgImage else {
            print("âš ï¸ CGImage ë³€í™˜ ì‹¤íŒ¨ - ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜")
            return image
        }
        
        let width = cgImage.width
        let height = cgImage.height
        let bytesPerPixel = 4
        let bytesPerRow = bytesPerPixel * width
        let bitsPerComponent = 8
        
        // ìƒ‰ìƒ ê³µê°„ ë° ë¹„íŠ¸ë§µ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        let colorSpace = CGColorSpaceCreateDeviceRGB()
        guard let context = CGContext(
            data: nil,
            width: width,
            height: height,
            bitsPerComponent: bitsPerComponent,
            bytesPerRow: bytesPerRow,
            space: colorSpace,
            bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue
        ) else {
            print("âš ï¸ CGContext ìƒì„± ì‹¤íŒ¨ - ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜")
            return image
        }
        
        // ì¢Œìš°ë°˜ì „ ë³€í™˜ ì ìš©
        context.scaleBy(x: -1.0, y: 1.0)
        context.translateBy(x: -CGFloat(width), y: 0)
        
        // ì´ë¯¸ì§€ ê·¸ë¦¬ê¸°
        context.draw(cgImage, in: CGRect(x: 0, y: 0, width: width, height: height))
        
        // ìƒˆë¡œìš´ CGImage ìƒì„±
        guard let flippedCGImage = context.makeImage() else {
            print("âš ï¸ ì¢Œìš°ë°˜ì „ëœ CGImage ìƒì„± ì‹¤íŒ¨ - ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜")
            return image
        }
        
        // UIImageë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        let flippedImage = UIImage(
            cgImage: flippedCGImage,
            scale: image.scale,
            orientation: image.imageOrientation
        )
        
        print("âœ… ì´ë¯¸ì§€ ì¢Œìš°ë°˜ì „ ì²˜ë¦¬ ì™„ë£Œ - ë¯¸ë¦¬ë³´ê¸°ì™€ ì¼ì¹˜")
        return flippedImage
    }
}

// ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìœ„í•œ í”Œëž«í¼ ë·° íŒ©í† ë¦¬
class CameraPreviewFactory: NSObject, FlutterPlatformViewFactory {
    private let captureSession: AVCaptureSession
    
    init(captureSession: AVCaptureSession) {
        self.captureSession = captureSession
        super.init()
    }
    
    func create(withFrame frame: CGRect, viewIdentifier viewId: Int64, arguments args: Any?) -> FlutterPlatformView {
        return CameraPreviewView(
            frame: frame,
            viewIdentifier: viewId,
            arguments: args,
            captureSession: captureSession
        )
    }
    
    func createArgsCodec() -> FlutterMessageCodec & NSObjectProtocol {
        return FlutterStandardMessageCodec.sharedInstance()
    }
}

// ë¯¸ë¦¬ë³´ê¸° ë·° ë ˆì´ì–´ í´ëž˜ìŠ¤
class PreviewView: UIView {
    override func layoutSubviews() {
        super.layoutSubviews()
        if let layer = layer as? AVCaptureVideoPreviewLayer {
            layer.videoGravity = .resizeAspectFill
            layer.connection?.videoOrientation = .portrait
            
            // ì „ë©´ ì¹´ë©”ë¼ì¼ ë•Œ ê±°ìš¸ ëª¨ë“œ ì„¤ì •
            if let connection = layer.connection {
                // ì „ë©´ ì¹´ë©”ë¼ì¼ ë•Œ ê±°ìš¸ ëª¨ë“œ í™œì„±í™” (ìžì—°ìŠ¤ëŸ¬ìš´ ì…€í”¼ ë¯¸ë¦¬ë³´ê¸°)
                if connection.isVideoMirroringSupported {
                    // ìžë™ ê±°ìš¸ ëª¨ë“œë¥¼ ë¨¼ì € ë¹„í™œì„±í™”
                    if connection.automaticallyAdjustsVideoMirroring {
                        connection.automaticallyAdjustsVideoMirroring = false
                    }
                    
                    // ì¹´ë©”ë¼ ìœ„ì¹˜ í™•ì¸
                    if let inputs = (layer.session?.inputs as? [AVCaptureDeviceInput]) {
                        let isFront = inputs.first?.device.position == .front
                        connection.isVideoMirrored = isFront
                        print("ðŸ”§ ë¯¸ë¦¬ë³´ê¸° ê±°ìš¸ ëª¨ë“œ: \(isFront ? "í™œì„±í™”" : "ë¹„í™œì„±í™”")")
                    }
                }
            }
        }
    }
    
    override class var layerClass: AnyClass {
        return AVCaptureVideoPreviewLayer.self
    }
}

// ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸° í”Œëž«í¼ ë·°
class CameraPreviewView: NSObject, FlutterPlatformView {
    private var _view: PreviewView
    
    init(frame: CGRect, viewIdentifier: Int64, arguments args: Any?, captureSession: AVCaptureSession) {
        _view = PreviewView(frame: frame)
        super.init()
        
        // ë·° ë ˆì´ì–´ ì„¤ì •
        if let previewLayer = _view.layer as? AVCaptureVideoPreviewLayer {
            previewLayer.session = captureSession
            previewLayer.videoGravity = .resizeAspectFill
            previewLayer.connection?.videoOrientation = .portrait
            
            // ì „ë©´ ì¹´ë©”ë¼ì¼ ë•Œ ê±°ìš¸ ëª¨ë“œ í™œì„±í™”
            if let connection = previewLayer.connection, connection.isVideoMirroringSupported {
                // ìžë™ ê±°ìš¸ ëª¨ë“œë¥¼ ë¨¼ì € ë¹„í™œì„±í™”
                if connection.automaticallyAdjustsVideoMirroring {
                    connection.automaticallyAdjustsVideoMirroring = false
                }
                
                // ì¹´ë©”ë¼ ìœ„ì¹˜ í™•ì¸ í›„ ê±°ìš¸ ëª¨ë“œ ì„¤ì •
                if let inputs = captureSession.inputs as? [AVCaptureDeviceInput] {
                    let isFront = inputs.first?.device.position == .front
                    connection.isVideoMirrored = isFront
                    print("ðŸ”§ ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸° ê±°ìš¸ ëª¨ë“œ: \(isFront ? "í™œì„±í™”" : "ë¹„í™œì„±í™”")")
                }
            }
        }
        
        _view.frame = frame
        _view.autoresizingMask = [.flexibleWidth, .flexibleHeight]
        
        // ì„¸ì…˜ì´ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë©´ ì‹œìž‘
        if !captureSession.isRunning {
            DispatchQueue.global(qos: .userInitiated).async {
                captureSession.startRunning()
            }
        }
    }
    
    func view() -> UIView {
        return _view
    }
}
